# AONP - Agent-Orchestrated Neutronics Platform

**Version 0.1.0**

An intelligent agentic orchestration system that automates nuclear simulation workflows, enabling researchers to focus on high-level physics rather than repetitive computational tasks.

---

## ğŸ¯ Problem Statement

Nuclear researchers with high skill levels spend significant time on monotonous, repetitive simulation tasks that don't leverage their expertise. These researchers must:

- Manually create and validate simulation configurations
- Write and debug XML input files for Monte Carlo simulations
- Monitor long-running simulations and manage execution
- Extract and process results from complex HDF5 outputs
- Track provenance and ensure reproducibility across studies
- Coordinate parameter sweeps and comparative analyses

These routine tasks consume valuable time that could be better spent on:
- Designing novel reactor concepts
- Analyzing physics phenomena
- Interpreting results and advancing scientific understanding
- Publishing research findings

**The Problem**: High-skilled researchers are trapped in low-value computational workflows instead of advancing nuclear science.

---

## ğŸ’¡ Solution: Agentic Orchestration

AONP (Agent-Orchestrated Neutronics Platform) provides an intelligent multi-agent system that automates the entire simulation workflow. Instead of manually creating configurations, managing runs, and processing results, researchers interact with the system through natural language queries or structured APIs.

### How It Works

The system uses a **LangGraph-based multi-agent orchestration** architecture:

1. **Router Agent**: Classifies user intent (simulation, parameter sweep, query, analysis)
2. **Specialist Agents**: Handle specific tasks with domain expertise
   - **Studies Agent**: Single simulation execution
   - **Sweep Agent**: Parameter sweep generation and management
   - **Query Agent**: Historical data search and retrieval
   - **Analysis Agent**: Result comparison and insights
3. **Tool Layer**: Interfaces with OpenMC simulation engine and MongoDB database
4. **Frontend**: Real-time visualization and interaction via Next.js web interface

### Key Capabilities

âœ… **Natural Language Interface**: Submit queries like "Simulate a PWR pin cell with 4.5% enriched UO2 at 600K"  
âœ… **Automated Configuration**: Agents generate validated OpenMC XML inputs from high-level specifications  
âœ… **Provenance Tracking**: Cryptographic hashing ensures complete reproducibility  
âœ… **Real-Time Monitoring**: Server-Sent Events (SSE) provide live simulation progress  
âœ… **Intelligent Result Extraction**: Automatic processing of HDF5 outputs to structured formats  
âœ… **Parameter Sweep Orchestration**: Automated generation and execution of multi-run studies  
âœ… **Historical Query System**: Search and compare past simulation results  
âœ… **RAG-Enhanced Assistance**: Context-aware help with nuclear engineering knowledge  

---

## ğŸ—ï¸ Architecture Overview

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AONP SYSTEM ARCHITECTURE                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

USER INTERFACE                    ORCHESTRATION LAYER          PHYSICS ENGINE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Natural Language Query
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js      â”‚â—„â”€â”€â”€â”€ Server-Sent Events (SSE)
â”‚  Frontend     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ HTTP/REST
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI     â”‚
â”‚   Backend     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LangGraph Multi-Agent System   â”‚
â”‚                                  â”‚
â”‚  Router â†’ Specialist Agents      â”‚
â”‚  (Studies | Sweep | Query |      â”‚
â”‚   Analysis)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ Tool Calls
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Tools Layer              â”‚      â”‚   MongoDB       â”‚
â”‚   - submit_study                 â”‚â”€â”€â”€â”€â”€â–¶â”‚   Database      â”‚
â”‚   - query_results                â”‚      â”‚   - studies     â”‚
â”‚   - generate_sweep               â”‚      â”‚   - runs        â”‚
â”‚   - compare_runs                 â”‚      â”‚   - summaries   â”‚
â”‚   - validate_physics             â”‚      â”‚   - events      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   OpenMC Integration Layer       â”‚
â”‚                                  â”‚
â”‚  1. YAML â†’ StudySpec (Pydantic)  â”‚
â”‚  2. StudySpec â†’ Canonical Hash   â”‚
â”‚  3. Hash â†’ Run Bundle            â”‚
â”‚  4. Bundle â†’ XML Generation      â”‚
â”‚  5. XML â†’ OpenMC Execution       â”‚
â”‚  6. HDF5 â†’ Result Extraction     â”‚
â”‚  7. Results â†’ MongoDB Storage    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    OpenMC     â”‚
â”‚  (Monte Carlo â”‚
â”‚   Neutron     â”‚
â”‚  Transport)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete Workflow Process

### OpenMC Integration Process

AONP integrates with OpenMC (MIT's Monte Carlo neutron transport code) through a comprehensive pipeline:

#### Step 1: User Input
- **Natural Language Query**: "Run a simulation of a PWR pin cell with 4.5% U-235 enrichment"
- **Structured YAML**: Submit a validated study specification
- **API Call**: Direct REST API submission

#### Step 2: Agent Orchestration
1. **Router Agent** classifies the query intent
2. **Specialist Agent** (e.g., Studies Agent) processes the request
3. Agent calls tools to:
   - Validate the physics specification
   - Check for duplicate studies (via hash lookup)
   - Generate or retrieve study configuration

#### Step 3: Study Specification
The system uses Pydantic schemas to create a validated `StudySpec` object:

```yaml
name: "pwr_pincell_4.5pct"
materials:
  fuel:
    density: 10.4  # g/cmÂ³
    nuclides:
      - {nuclide: "U235", fraction: 0.045}
      - {nuclide: "U238", fraction: 0.955}
  cladding:
    density: 6.56
    nuclides:
      - {nuclide: "Zr", fraction: 1.0}
geometry:
  script: "pincell_geometry.py"
  parameters:
    pitch: 1.26  # cm
    fuel_radius: 0.4096  # cm
settings:
  particles: 10000
  batches: 50
  inactive: 10
nuclear_data:
  library: "endfb-vii.1"
```

#### Step 4: Canonical Hashing
- StudySpec is converted to canonical JSON (sorted keys)
- SHA256 hash is computed for reproducibility
- Hash enables duplicate detection and result lookup

#### Step 5: Run Bundle Creation
Self-contained execution directory structure:

```
runs/run_{hash}/
â”œâ”€â”€ study_spec.json          # Canonical specification
â”œâ”€â”€ run_manifest.json        # Provenance metadata
â”œâ”€â”€ nuclear_data.ref.json    # Data library references
â”œâ”€â”€ inputs/
â”‚   â”œâ”€â”€ materials.xml        # Generated OpenMC XML
â”‚   â”œâ”€â”€ geometry.xml         # Generated from Python script
â”‚   â”œâ”€â”€ settings.xml         # Monte Carlo settings
â”‚   â””â”€â”€ geometry_script.py   # Copied for reproducibility
â””â”€â”€ outputs/
    â”œâ”€â”€ statepoint.50.h5     # OpenMC results
    â”œâ”€â”€ summary.h5           # Summary data
    â””â”€â”€ openmc_stdout.log    # Execution log
```

#### Step 6: XML Generation
- **Materials XML**: Generated from material specifications
- **Geometry XML**: Executed from Python geometry scripts
- **Settings XML**: Monte Carlo parameters (particles, batches, etc.)

#### Step 7: OpenMC Execution
- Environment configured (cross-section paths, threading)
- OpenMC solver runs Monte Carlo neutron transport
- Results written to HDF5 format (statepoint files)

#### Step 8: Result Extraction
- HDF5 files processed to extract:
  - k-effective (multiplication factor)
  - Uncertainties and confidence intervals
  - Batch statistics
  - Tally results (if configured)
- Results stored in Parquet format for efficient querying

#### Step 9: Database Storage
Results stored in MongoDB:
- **studies**: Deduplicated study specifications
- **runs**: Execution state and metadata
- **summaries**: Lightweight result summaries
- **events**: Audit log of all operations

#### Step 10: User Notification
- Real-time updates via SSE streams
- Results available through REST API
- Frontend visualization of results

---

## ğŸ“¦ Project Structure

```
Hackathon_fusion/
â”œâ”€â”€ aonp/                          # Core AONP package
â”‚   â”œâ”€â”€ schemas/                   # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ study.py               # StudySpec with deterministic hashing
â”‚   â”‚   â””â”€â”€ manifest.py            # RunManifest (provenance record)
â”‚   â”œâ”€â”€ core/                      # Core utilities
â”‚   â”‚   â”œâ”€â”€ bundler.py             # Creates canonical run bundles
â”‚   â”‚   â””â”€â”€ extractor.py           # Post-processing (H5 â†’ Parquet)
â”‚   â”œâ”€â”€ db/                        # MongoDB persistence layer
â”‚   â”‚   â”œâ”€â”€ mongo.py               # Database operations
â”‚   â”‚   â””â”€â”€ README.md              # Database documentation
â”‚   â”œâ”€â”€ runner/                    # Execution logic
â”‚   â”‚   â”œâ”€â”€ entrypoint.py          # OpenMC simulation runner
â”‚   â”‚   â””â”€â”€ Dockerfile             # Container environment
â”‚   â”œâ”€â”€ api/                       # REST API
â”‚   â”‚   â””â”€â”€ main.py                # FastAPI application
â”‚   â””â”€â”€ examples/                  # Example studies
â”‚       â”œâ”€â”€ simple_pincell.yaml
â”‚       â””â”€â”€ pincell_geometry.py
â”‚
â”œâ”€â”€ Playground/                    # Agent orchestration system
â”‚   â””â”€â”€ backend/
â”‚       â”œâ”€â”€ graphs/                # LangGraph state machines
â”‚       â”‚   â””â”€â”€ query_graph.py     # Main query orchestration
â”‚       â”œâ”€â”€ multi_agent_system.py  # Router + specialist agents
â”‚       â”œâ”€â”€ agent_tools.py         # MongoDB simulation tools
â”‚       â”œâ”€â”€ openmc_adapter.py      # OpenMC integration adapter
â”‚       â””â”€â”€ api/
â”‚           â”œâ”€â”€ main.py            # FastAPI server
â”‚           â”œâ”€â”€ main_v2.py         # Enhanced API with agents
â”‚           â””â”€â”€ rag_endpoints.py   # RAG-enhanced endpoints
â”‚
â”œâ”€â”€ frontend/                      # Next.js web interface
â”‚   â”œâ”€â”€ app/                       # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ page.tsx               # Main application page
â”‚   â”‚   â””â”€â”€ layout.tsx             # App layout
â”‚   â”œâ”€â”€ components/                # React components
â”‚   â”‚   â”œâ”€â”€ RAGCopilotPanel.tsx    # Main chat interface
â”‚   â”‚   â””â”€â”€ RAGAgentCard.tsx       # Agent status cards
â”‚   â”œâ”€â”€ hooks/                     # React hooks
â”‚   â”‚   â”œâ”€â”€ useEventStream.ts      # SSE event streaming
â”‚   â”‚   â””â”€â”€ useQueryHistory.ts     # Query history management
â”‚   â””â”€â”€ lib/                       # Utilities
â”‚       â”œâ”€â”€ api.ts                 # API client
â”‚       â””â”€â”€ types.ts               # TypeScript types
â”‚
â”œâ”€â”€ verification_studies/          # Validation test cases
â”‚   â”œâ”€â”€ 01_toy_geometry.py
â”‚   â”œâ”€â”€ 02_single_torus.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ openmc_design.md               # OpenMC integration design doc
â”œâ”€â”€ OPENMC_API_SPEC.md             # API specification
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ pyproject.toml                 # Project metadata
â””â”€â”€ README.md                      # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** (3.10+ recommended)
- **Node.js 18+** (for frontend)
- **MongoDB** (Atlas cloud or local instance)
- **Linux/macOS** (OpenMC requires Linux/macOS; Windows users should use WSL2)

### Installation

#### 1. Backend Setup

```bash
# Clone repository
git clone <repository-url>
cd Hackathon_fusion

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install OpenMC (Linux/macOS only)
# Option 1: Conda (recommended)
conda install -c conda-forge openmc

# Option 2: pip (may require system dependencies)
pip install openmc

# Configure environment
cp Playground/backend/env_example.txt .env
# Edit .env with your MongoDB URI and API keys
```

#### 2. MongoDB Setup

```bash
# Option 1: MongoDB Atlas (Cloud - Free tier available)
# 1. Sign up at https://www.mongodb.com/cloud/atlas/register
# 2. Create a cluster
# 3. Get connection string
# 4. Add to .env: MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net/

# Option 2: Local MongoDB
# Install MongoDB locally and use: MONGODB_URI=mongodb://localhost:27017/

# Initialize database
python scripts/init_db.py

# Test connection
python scripts/test_db.py
```

#### 3. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Configure environment (create .env.local)
echo "NEXT_PUBLIC_API_URL=http://localhost:8000" > .env.local

# Start development server
npm run dev
# Frontend available at http://localhost:3000
```

#### 4. Start Backend API

```bash
cd Playground/backend

# Start FastAPI server
python api/main_v2.py
# Or with uvicorn directly:
uvicorn api.main_v2:app --reload --host 0.0.0.0 --port 8000

# API available at http://localhost:8000
# API docs at http://localhost:8000/docs
```

### Usage Examples

#### Natural Language Query (via API)

```bash
curl -X POST "http://localhost:8000/api/v1/requests" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Simulate a PWR pin cell with 4.5% enriched UO2 fuel at 600K"
  }'
```

#### Direct Study Submission (YAML)

```bash
curl -X POST "http://localhost:8000/api/v1/studies" \
  -F "file=@aonp/examples/simple_pincell.yaml"
```

#### Query Simulation Results

```bash
# Get run by ID
curl "http://localhost:8000/api/v1/runs/{run_id}"

# Search runs
curl "http://localhost:8000/api/v1/runs?geometry=pincell&enrichment_min=4.0"
```

---

## ğŸ“‹ Current Project Specifications

### Technology Stack

**Backend**:
- Python 3.10+
- FastAPI (async REST API framework)
- LangGraph (multi-agent orchestration)
- Pydantic v2 (data validation)
- Motor (async MongoDB driver)
- Fireworks AI (LLM provider)

**Frontend**:
- Next.js 15 (React framework)
- TypeScript
- Tailwind CSS
- Server-Sent Events (SSE) for real-time updates

**Simulation Engine**:
- OpenMC 0.14+ (Monte Carlo neutron transport)
- ENDF/B-VII.1 nuclear data library

**Database**:
- MongoDB (state, results, provenance)
- ChromaDB (optional, for RAG vector storage)

### Key Features Implemented

âœ… **Multi-Agent Orchestration**
- Router agent for intent classification
- Specialist agents (Studies, Sweep, Query, Analysis)
- LangGraph state machine for workflow management

âœ… **OpenMC Integration**
- YAML â†’ StudySpec validation
- Canonical hashing for reproducibility
- XML generation from specifications
- HDF5 result extraction
- MongoDB persistence

âœ… **REST API**
- Natural language query endpoints
- Direct study submission
- Run status and results retrieval
- Real-time SSE streaming

âœ… **Frontend Interface**
- Next.js web application
- Real-time agent progress visualization
- Query history and result display
- RAG-enhanced chat interface

âœ… **Provenance Tracking**
- Cryptographic input hashing
- Complete run manifests
- Audit logging
- Reproducible execution

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/requests` | POST | Submit natural language query |
| `/api/v1/requests/{id}` | GET | Get query status |
| `/api/v1/requests/{id}/stream` | GET | Stream agent progress (SSE) |
| `/api/v1/studies` | POST | Submit study directly (YAML) |
| `/api/v1/runs` | GET | Query simulation runs |
| `/api/v1/runs/{id}` | GET | Get specific run details |
| `/api/v1/runs/compare` | POST | Compare multiple runs |
| `/api/v1/statistics` | GET | Database statistics |
| `/api/v1/health` | GET | Health check |

Full API documentation available at `/docs` when server is running.

---

## ğŸ“š Documentation

### Core Documentation

- **[openmc_design.md](openmc_design.md)** - Complete OpenMC integration design document
- **[OPENMC_API_SPEC.md](OPENMC_API_SPEC.md)** - API specification (superseded, see design doc)
- **[Playground/backend/README_MULTI_AGENT.md](Playground/backend/README_MULTI_AGENT.md)** - Multi-agent system guide
- **[Playground/backend/README_API.md](Playground/backend/README_API.md)** - Backend API documentation
- **[aonp/db/README.md](aonp/db/README.md)** - MongoDB schema and usage

### Frontend Documentation

- **[frontend/RAG_FRONTEND_SHOWCASE.md](frontend/RAG_FRONTEND_SHOWCASE.md)** - RAG frontend features
- **[frontend/MISSION_CONTROL_MVP_PLAN.md](frontend/MISSION_CONTROL_MVP_PLAN.md)** - Mission control interface plan

### Implementation Summaries

- **[IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md)** - OpenMC integration implementation
- **[INTEGRATION_SUMMARY.md](INTEGRATION_SUMMARY.md)** - System integration summary

---

## ğŸ§ª Testing

### Backend Tests

```bash
cd Playground/backend
pytest tests/
```

### Integration Tests

```bash
# Run end-to-end tests
pytest tests/test_integration_complete.py

# Test MongoDB integration
python scripts/test_db.py

# Test OpenMC adapter
python -m pytest tests/test_adapter_e2e.py
```

### Verification Studies

```bash
cd verification_studies
python run_all_studies.py
```

---

## ğŸ” Environment Variables

### Backend `.env` (in project root)

```bash
# MongoDB
MONGODB_URI=mongodb+srv://user:pass@cluster.mongodb.net/
MONGODB_DB=aonp_db

# LLM Provider (Fireworks AI)
FIREWORKS_API_KEY=your_fireworks_api_key

# Optional: RAG
VOYAGE_API_KEY=your_voyage_api_key  # For embeddings

# Optional: LangSmith Tracing
LANGCHAIN_API_KEY=your_langsmith_api_key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=aonp

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000
```

### Frontend `.env.local` (in frontend/)

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## ğŸ³ Docker Usage

### Build Backend Image

```bash
docker build -t aonp-backend -f aonp/runner/Dockerfile .
```

### Run Backend Container

```bash
docker run -p 8000:8000 \
  -e MONGODB_URI=mongodb+srv://... \
  -e FIREWORKS_API_KEY=... \
  --env-file .env \
  aonp-backend
```

---

## ğŸš§ Roadmap

### Completed âœ…

- [x] Core AONP package with Pydantic schemas
- [x] OpenMC integration (bundling, XML generation, execution)
- [x] MongoDB persistence layer
- [x] Multi-agent orchestration system (LangGraph)
- [x] FastAPI REST API
- [x] Next.js frontend with real-time updates
- [x] RAG-enhanced assistance system
- [x] Provenance tracking with cryptographic hashing

### In Progress ğŸš§

- [ ] Advanced parameter sweep UI
- [ ] Enhanced result visualization
- [ ] Multi-user authentication
- [ ] Production deployment guides

### Planned ğŸ“‹

- [ ] Distributed execution (Celery/Ray)
- [ ] Advanced geometry DSL
- [ ] Tally specification in YAML
- [ ] Integration with other neutronics codes
- [ ] Performance optimization for large-scale studies

---

## ğŸ¤ Contributing

This project follows high-integrity scientific computing principles:

1. **Deterministic behavior**: No hidden randomness
2. **Schema-first design**: Pydantic validation for all data
3. **Provenance tracking**: Every result traceable to inputs
4. **Type safety**: Type hints and validation throughout
5. **Comprehensive testing**: Unit, integration, and verification tests

---

## ğŸ“„ License

MIT License

---

## ğŸ™ Acknowledgments

- **OpenMC Team**: Built on [OpenMC](https://openmc.org) - MIT's Monte Carlo particle transport code
- **LangChain/LangGraph**: Multi-agent orchestration framework
- **Fireworks AI**: LLM inference infrastructure
- **MongoDB**: Database and persistence layer

---

## ğŸ“§ Contact

For questions, contributions, or collaboration inquiries, please contact:

**Matthew Robillard**  
Email: **robillard.matthew22@berkeley.edu**

---

**Last Updated**: January 2026  
**Version**: 0.1.0
